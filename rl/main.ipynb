{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board(gym.Env):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, action):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:01:16,210\tWARNING deprecation.py:50 -- DeprecationWarning: `build_tf_policy` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:01:16,219\tWARNING deprecation.py:50 -- DeprecationWarning: `build_policy_class` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,224\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/simple_q/` has been deprecated. Use `rllib_contrib/simple_q/` instead. This will raise an error in the future!\n",
      "c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "2023-08-01 15:01:16,272\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,274\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,289\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.get_torch_categorical_class_with_temperature` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,290\tWARNING deprecation.py:50 -- DeprecationWarning: `TorchPolicy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,294\tWARNING deprecation.py:50 -- DeprecationWarning: `EpsilonGreedy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,295\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,297\tWARNING deprecation.py:50 -- DeprecationWarning: `TargetNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,305\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-01 15:01:16,319\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ray.rllib.algorithms.dqn.dqn.DQNConfig object at 0x000002115C37F400>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:01:20,599\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 1000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.01042534907658895\n",
      "  StateBufferConnector_ms: 0.014575322469075521\n",
      "  ViewRequirementAgentConnector_ms: 0.15203158060709634\n",
      "counters:\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 0\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_trained: 0\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-01-20\n",
      "done: false\n",
      "episode_len_mean: 20.583333333333332\n",
      "episode_media: {}\n",
      "episode_reward_max: 62.0\n",
      "episode_reward_mean: 20.583333333333332\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 48\n",
      "episodes_total: 48\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  learner: {}\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 0\n",
      "  num_env_steps_sampled: 1000\n",
      "  num_env_steps_trained: 0\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 1000\n",
      "num_agent_steps_trained: 0\n",
      "num_env_steps_sampled: 1000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 239.314557840487\n",
      "num_env_steps_trained: 0\n",
      "num_env_steps_trained_this_iter: 0\n",
      "num_env_steps_trained_throughput_per_sec: 0.0\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 0\n",
      "perf:\n",
      "  cpu_util_percent: 67.76666666666667\n",
      "  ram_util_percent: 49.1\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.18777237548218384\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07689296901523769\n",
      "  mean_inference_ms: 1.746292476292019\n",
      "  mean_raw_obs_processing_ms: 1.0940645124528794\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.01042534907658895\n",
      "    StateBufferConnector_ms: 0.014575322469075521\n",
      "    ViewRequirementAgentConnector_ms: 0.15203158060709634\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 20.583333333333332\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 62.0\n",
      "  episode_reward_mean: 20.583333333333332\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 48\n",
      "  hist_stats:\n",
      "    episode_lengths: [31, 12, 25, 47, 28, 17, 23, 18, 10, 15, 15, 23, 23, 23, 19,\n",
      "      18, 24, 19, 9, 62, 18, 26, 13, 23, 15, 31, 17, 16, 16, 12, 17, 39, 15, 16, 34,\n",
      "      12, 28, 17, 16, 21, 18, 13, 12, 25, 12, 23, 12, 10]\n",
      "    episode_reward: [31.0, 12.0, 25.0, 47.0, 28.0, 17.0, 23.0, 18.0, 10.0, 15.0, 15.0,\n",
      "      23.0, 23.0, 23.0, 19.0, 18.0, 24.0, 19.0, 9.0, 62.0, 18.0, 26.0, 13.0, 23.0,\n",
      "      15.0, 31.0, 17.0, 16.0, 16.0, 12.0, 17.0, 39.0, 15.0, 16.0, 34.0, 12.0, 28.0,\n",
      "      17.0, 16.0, 21.0, 18.0, 13.0, 12.0, 25.0, 12.0, 23.0, 12.0, 10.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18777237548218384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07689296901523769\n",
      "    mean_inference_ms: 1.746292476292019\n",
      "    mean_raw_obs_processing_ms: 1.0940645124528794\n",
      "time_since_restore: 4.180600643157959\n",
      "time_this_iter_s: 4.180600643157959\n",
      "time_total_s: 4.180600643157959\n",
      "timers:\n",
      "  sample_time_ms: 2.6\n",
      "  training_iteration_time_ms: 2.9\n",
      "timestamp: 1690869680\n",
      "timesteps_total: 1000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 2000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.018010616302490234\n",
      "  StateBufferConnector_ms: 0.01499629020690918\n",
      "  ViewRequirementAgentConnector_ms: 0.1776878833770752\n",
      "counters:\n",
      "  last_target_update_ts: 1501\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_env_steps_sampled: 2000\n",
      "  num_env_steps_trained: 32000\n",
      "  num_target_updates: 2\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-01-56\n",
      "done: false\n",
      "episode_len_mean: 19.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 62.0\n",
      "episode_reward_mean: 19.93\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 52\n",
      "episodes_total: 100\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 1501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 658.90625\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.18647733330726624\n",
      "        max_q: 3.339219570159912\n",
      "        mean_q: 2.4314656257629395\n",
      "        min_q: 1.6688005924224854\n",
      "      mean_td_error: 0.19610796868801117\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 1000.0\n",
      "      td_error: [0.15024948120117188, 0.07446980476379395, 1.1437294483184814, 0.18262076377868652,\n",
      "        0.07446980476379395, 0.39586973190307617, 0.5469183921813965, 0.06775617599487305,\n",
      "        0.031047582626342773, -0.19589996337890625, -0.19288015365600586, 0.9493281841278076,\n",
      "        -0.1337873935699463, -0.06447935104370117, 0.11679911613464355, 0.6867128610610962,\n",
      "        -0.16634631156921387, 0.7679035663604736, -0.2690962553024292, 0.2014777660369873,\n",
      "        0.0028493404388427734, 0.12444210052490234, 0.34375977516174316, 1.1437294483184814,\n",
      "        -0.13057637214660645, -0.3579897880554199, 0.06209850311279297, 0.018064498901367188,\n",
      "        -0.10369157791137695, 0.032156944274902344, 0.6688005924224854, 0.10494804382324219]\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_env_steps_sampled: 2000\n",
      "  num_env_steps_trained: 32000\n",
      "  num_target_updates: 2\n",
      "iterations_since_restore: 2\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 2000\n",
      "num_agent_steps_trained: 32000\n",
      "num_env_steps_sampled: 2000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 27.83703245238852\n",
      "num_env_steps_trained: 32000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 890.7850384764326\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 56.461999999999996\n",
      "  ram_util_percent: 49.09\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.18703728116264273\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.09094590892987084\n",
      "  mean_inference_ms: 1.8414304601819833\n",
      "  mean_raw_obs_processing_ms: 1.1495675851443001\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.018010616302490234\n",
      "    StateBufferConnector_ms: 0.01499629020690918\n",
      "    ViewRequirementAgentConnector_ms: 0.1776878833770752\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 19.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 62.0\n",
      "  episode_reward_mean: 19.93\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 52\n",
      "  hist_stats:\n",
      "    episode_lengths: [31, 12, 25, 47, 28, 17, 23, 18, 10, 15, 15, 23, 23, 23, 19,\n",
      "      18, 24, 19, 9, 62, 18, 26, 13, 23, 15, 31, 17, 16, 16, 12, 17, 39, 15, 16, 34,\n",
      "      12, 28, 17, 16, 21, 18, 13, 12, 25, 12, 23, 12, 10, 17, 18, 12, 30, 12, 10,\n",
      "      15, 12, 25, 13, 18, 13, 25, 15, 14, 16, 11, 35, 23, 31, 16, 15, 15, 27, 18,\n",
      "      21, 37, 10, 17, 21, 20, 23, 14, 11, 11, 10, 16, 17, 11, 34, 29, 19, 13, 34,\n",
      "      12, 23, 50, 19, 9, 29, 28, 11]\n",
      "    episode_reward: [31.0, 12.0, 25.0, 47.0, 28.0, 17.0, 23.0, 18.0, 10.0, 15.0, 15.0,\n",
      "      23.0, 23.0, 23.0, 19.0, 18.0, 24.0, 19.0, 9.0, 62.0, 18.0, 26.0, 13.0, 23.0,\n",
      "      15.0, 31.0, 17.0, 16.0, 16.0, 12.0, 17.0, 39.0, 15.0, 16.0, 34.0, 12.0, 28.0,\n",
      "      17.0, 16.0, 21.0, 18.0, 13.0, 12.0, 25.0, 12.0, 23.0, 12.0, 10.0, 17.0, 18.0,\n",
      "      12.0, 30.0, 12.0, 10.0, 15.0, 12.0, 25.0, 13.0, 18.0, 13.0, 25.0, 15.0, 14.0,\n",
      "      16.0, 11.0, 35.0, 23.0, 31.0, 16.0, 15.0, 15.0, 27.0, 18.0, 21.0, 37.0, 10.0,\n",
      "      17.0, 21.0, 20.0, 23.0, 14.0, 11.0, 11.0, 10.0, 16.0, 17.0, 11.0, 34.0, 29.0,\n",
      "      19.0, 13.0, 34.0, 12.0, 23.0, 50.0, 19.0, 9.0, 29.0, 28.0, 11.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18703728116264273\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.09094590892987084\n",
      "    mean_inference_ms: 1.8414304601819833\n",
      "    mean_raw_obs_processing_ms: 1.1495675851443001\n",
      "time_since_restore: 40.10597109794617\n",
      "time_this_iter_s: 35.92537045478821\n",
      "time_total_s: 40.10597109794617\n",
      "timers:\n",
      "  learn_throughput: 3333.004\n",
      "  learn_time_ms: 9.601\n",
      "  load_throughput: 159935.329\n",
      "  load_time_ms: 0.2\n",
      "  sample_time_ms: 3.662\n",
      "  synch_weights_time_ms: 0.3\n",
      "  training_iteration_time_ms: 32.76\n",
      "timestamp: 1690869716\n",
      "timesteps_total: 2000\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 3000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.021025896072387695\n",
      "  StateBufferConnector_ms: 0.00800013542175293\n",
      "  ViewRequirementAgentConnector_ms: 0.21584415435791016\n",
      "counters:\n",
      "  last_target_update_ts: 2501\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_trained: 64000\n",
      "  num_target_updates: 4\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-02-31\n",
      "done: false\n",
      "episode_len_mean: 19.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 52.0\n",
      "episode_reward_mean: 19.99\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 47\n",
      "episodes_total: 147\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 2501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 1337.875\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.23393194377422333\n",
      "        max_q: 5.618791103363037\n",
      "        mean_q: 3.685421943664551\n",
      "        min_q: 1.499876856803894\n",
      "      mean_td_error: 0.22346040606498718\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 2000.0\n",
      "      td_error: [0.19253969192504883, 0.8235055208206177, 0.12726497650146484, -0.13471078872680664,\n",
      "        0.16386175155639648, 0.04721879959106445, 0.024701356887817383, 0.0007166862487792969,\n",
      "        0.49987685680389404, 0.0636587142944336, 0.06493711471557617, 1.1123409271240234,\n",
      "        0.09934329986572266, -0.17985749244689941, 0.22932147979736328, 0.20194625854492188,\n",
      "        0.6760578155517578, 0.1617288589477539, 0.02858448028564453, 0.003760814666748047,\n",
      "        0.7258167266845703, 0.0914602279663086, 0.12635183334350586, -0.11425995826721191,\n",
      "        -0.25332045555114746, 0.8611407279968262, -0.008778095245361328, 1.1431548595428467,\n",
      "        0.039139747619628906, -0.03935432434082031, 0.2147355079650879, 0.15784883499145508]\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_trained: 64000\n",
      "  num_target_updates: 4\n",
      "iterations_since_restore: 3\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 3000\n",
      "num_agent_steps_trained: 64000\n",
      "num_env_steps_sampled: 3000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.31242979149515\n",
      "num_env_steps_trained: 64000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 905.9977533278447\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 58.579591836734686\n",
      "  ram_util_percent: 49.02857142857142\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.1879121955150019\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10203680054281428\n",
      "  mean_inference_ms: 1.9700055705799202\n",
      "  mean_raw_obs_processing_ms: 1.2123707600535305\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.021025896072387695\n",
      "    StateBufferConnector_ms: 0.00800013542175293\n",
      "    ViewRequirementAgentConnector_ms: 0.21584415435791016\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 19.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 52.0\n",
      "  episode_reward_mean: 19.99\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 47\n",
      "  hist_stats:\n",
      "    episode_lengths: [10, 17, 18, 12, 30, 12, 10, 15, 12, 25, 13, 18, 13, 25, 15,\n",
      "      14, 16, 11, 35, 23, 31, 16, 15, 15, 27, 18, 21, 37, 10, 17, 21, 20, 23, 14,\n",
      "      11, 11, 10, 16, 17, 11, 34, 29, 19, 13, 34, 12, 23, 50, 19, 9, 29, 28, 11, 42,\n",
      "      27, 17, 20, 12, 24, 38, 18, 11, 24, 10, 12, 52, 28, 13, 25, 16, 12, 25, 21,\n",
      "      11, 29, 25, 12, 10, 16, 11, 15, 20, 28, 15, 16, 41, 18, 29, 31, 10, 29, 18,\n",
      "      15, 24, 11, 17, 15, 17, 39, 15]\n",
      "    episode_reward: [10.0, 17.0, 18.0, 12.0, 30.0, 12.0, 10.0, 15.0, 12.0, 25.0, 13.0,\n",
      "      18.0, 13.0, 25.0, 15.0, 14.0, 16.0, 11.0, 35.0, 23.0, 31.0, 16.0, 15.0, 15.0,\n",
      "      27.0, 18.0, 21.0, 37.0, 10.0, 17.0, 21.0, 20.0, 23.0, 14.0, 11.0, 11.0, 10.0,\n",
      "      16.0, 17.0, 11.0, 34.0, 29.0, 19.0, 13.0, 34.0, 12.0, 23.0, 50.0, 19.0, 9.0,\n",
      "      29.0, 28.0, 11.0, 42.0, 27.0, 17.0, 20.0, 12.0, 24.0, 38.0, 18.0, 11.0, 24.0,\n",
      "      10.0, 12.0, 52.0, 28.0, 13.0, 25.0, 16.0, 12.0, 25.0, 21.0, 11.0, 29.0, 25.0,\n",
      "      12.0, 10.0, 16.0, 11.0, 15.0, 20.0, 28.0, 15.0, 16.0, 41.0, 18.0, 29.0, 31.0,\n",
      "      10.0, 29.0, 18.0, 15.0, 24.0, 11.0, 17.0, 15.0, 17.0, 39.0, 15.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1879121955150019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10203680054281428\n",
      "    mean_inference_ms: 1.9700055705799202\n",
      "    mean_raw_obs_processing_ms: 1.2123707600535305\n",
      "time_since_restore: 75.42814612388611\n",
      "time_this_iter_s: 35.32217502593994\n",
      "time_total_s: 75.42814612388611\n",
      "timers:\n",
      "  learn_throughput: 2847.137\n",
      "  learn_time_ms: 11.239\n",
      "  load_throughput: 67112.22\n",
      "  load_time_ms: 0.477\n",
      "  sample_time_ms: 4.399\n",
      "  synch_weights_time_ms: 0.0\n",
      "  training_iteration_time_ms: 37.405\n",
      "timestamp: 1690869751\n",
      "timesteps_total: 3000\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 4000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.017016172409057617\n",
      "  StateBufferConnector_ms: 0.0049991607666015625\n",
      "  ViewRequirementAgentConnector_ms: 0.19471025466918945\n",
      "counters:\n",
      "  last_target_update_ts: 3501\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 96000\n",
      "  num_target_updates: 6\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-03-06\n",
      "done: false\n",
      "episode_len_mean: 23.77\n",
      "episode_media: {}\n",
      "episode_reward_max: 75.0\n",
      "episode_reward_mean: 23.77\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 35\n",
      "episodes_total: 182\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 3501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 1687.15625\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.18090294301509857\n",
      "        max_q: 7.502840042114258\n",
      "        mean_q: 5.016637802124023\n",
      "        min_q: 1.6903040409088135\n",
      "      mean_td_error: 0.08192265033721924\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 3000.0\n",
      "      td_error: [0.0683283805847168, 0.3520956039428711, -0.4224419593811035, 0.2536497116088867,\n",
      "        0.10233497619628906, 0.5990419387817383, -0.3096175193786621, -0.2637343406677246,\n",
      "        0.30579662322998047, -0.10814619064331055, 0.8978350162506104, 0.6903040409088135,\n",
      "        0.7626057863235474, 0.26824045181274414, 0.26801013946533203, -0.44536352157592773,\n",
      "        0.17536258697509766, -0.26580142974853516, 0.4189760684967041, 0.002177715301513672,\n",
      "        -1.0691313743591309, 0.1482372283935547, 0.08731460571289062, 0.09890604019165039,\n",
      "        -0.4711589813232422, 0.20289325714111328, 0.24744796752929688, -0.054975032806396484,\n",
      "        0.08904886245727539, 0.015605449676513672, 0.17801475524902344, -0.2003321647644043]\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 96000\n",
      "  num_target_updates: 6\n",
      "iterations_since_restore: 4\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 4000\n",
      "num_agent_steps_trained: 96000\n",
      "num_env_steps_sampled: 4000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.73969778951487\n",
      "num_env_steps_trained: 96000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 919.6703292644759\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 59.34791666666666\n",
      "  ram_util_percent: 49.387499999999996\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.1888741943160943\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10262091466912039\n",
      "  mean_inference_ms: 2.01267024621856\n",
      "  mean_raw_obs_processing_ms: 1.2233751125131989\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.017016172409057617\n",
      "    StateBufferConnector_ms: 0.0049991607666015625\n",
      "    ViewRequirementAgentConnector_ms: 0.19471025466918945\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 23.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 75.0\n",
      "  episode_reward_mean: 23.77\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 35\n",
      "  hist_stats:\n",
      "    episode_lengths: [11, 10, 16, 17, 11, 34, 29, 19, 13, 34, 12, 23, 50, 19, 9, 29,\n",
      "      28, 11, 42, 27, 17, 20, 12, 24, 38, 18, 11, 24, 10, 12, 52, 28, 13, 25, 16,\n",
      "      12, 25, 21, 11, 29, 25, 12, 10, 16, 11, 15, 20, 28, 15, 16, 41, 18, 29, 31,\n",
      "      10, 29, 18, 15, 24, 11, 17, 15, 17, 39, 15, 25, 21, 11, 15, 14, 28, 35, 37,\n",
      "      36, 27, 24, 12, 64, 12, 69, 24, 19, 25, 13, 18, 33, 26, 15, 75, 50, 75, 15,\n",
      "      24, 41, 12, 25, 22, 53, 13, 10]\n",
      "    episode_reward: [11.0, 10.0, 16.0, 17.0, 11.0, 34.0, 29.0, 19.0, 13.0, 34.0, 12.0,\n",
      "      23.0, 50.0, 19.0, 9.0, 29.0, 28.0, 11.0, 42.0, 27.0, 17.0, 20.0, 12.0, 24.0,\n",
      "      38.0, 18.0, 11.0, 24.0, 10.0, 12.0, 52.0, 28.0, 13.0, 25.0, 16.0, 12.0, 25.0,\n",
      "      21.0, 11.0, 29.0, 25.0, 12.0, 10.0, 16.0, 11.0, 15.0, 20.0, 28.0, 15.0, 16.0,\n",
      "      41.0, 18.0, 29.0, 31.0, 10.0, 29.0, 18.0, 15.0, 24.0, 11.0, 17.0, 15.0, 17.0,\n",
      "      39.0, 15.0, 25.0, 21.0, 11.0, 15.0, 14.0, 28.0, 35.0, 37.0, 36.0, 27.0, 24.0,\n",
      "      12.0, 64.0, 12.0, 69.0, 24.0, 19.0, 25.0, 13.0, 18.0, 33.0, 26.0, 15.0, 75.0,\n",
      "      50.0, 75.0, 15.0, 24.0, 41.0, 12.0, 25.0, 22.0, 53.0, 13.0, 10.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1888741943160943\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10262091466912039\n",
      "    mean_inference_ms: 2.01267024621856\n",
      "    mean_raw_obs_processing_ms: 1.2233751125131989\n",
      "time_since_restore: 110.22421884536743\n",
      "time_this_iter_s: 34.79607272148132\n",
      "time_total_s: 110.22421884536743\n",
      "timers:\n",
      "  learn_throughput: 3404.07\n",
      "  learn_time_ms: 9.401\n",
      "  load_throughput: 106818.725\n",
      "  load_time_ms: 0.3\n",
      "  sample_time_ms: 4.002\n",
      "  synch_weights_time_ms: 0.2\n",
      "  training_iteration_time_ms: 30.8\n",
      "timestamp: 1690869786\n",
      "timesteps_total: 4000\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 5000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.010008096694946289\n",
      "  StateBufferConnector_ms: 0.00099945068359375\n",
      "  ViewRequirementAgentConnector_ms: 0.19654512405395508\n",
      "counters:\n",
      "  last_target_update_ts: 4501\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_env_steps_sampled: 5000\n",
      "  num_env_steps_trained: 128000\n",
      "  num_target_updates: 8\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-03-41\n",
      "done: false\n",
      "episode_len_mean: 26.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 87.0\n",
      "episode_reward_mean: 26.38\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 33\n",
      "episodes_total: 215\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 4501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 2038.28125\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.14254434406757355\n",
      "        max_q: 8.864744186401367\n",
      "        mean_q: 5.932100772857666\n",
      "        min_q: 0.46705830097198486\n",
      "      mean_td_error: 0.121346116065979\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 4000.0\n",
      "      td_error: [0.05421638488769531, 0.1466073989868164, -0.2177104949951172, -0.11277103424072266,\n",
      "        -0.07468128204345703, -0.11389636993408203, -0.19766616821289062, -0.053063392639160156,\n",
      "        0.6933221817016602, -0.04053688049316406, 0.08238792419433594, -0.30651092529296875,\n",
      "        -0.3501243591308594, 0.0014238357543945312, -0.08970952033996582, 0.46331000328063965,\n",
      "        -0.30031776428222656, 2.115117073059082, -0.08197402954101562, -0.04274177551269531,\n",
      "        -0.20434999465942383, -0.08401906490325928, -0.14771509170532227, 3.5276060104370117,\n",
      "        -0.2934226989746094, 0.4234466552734375, 1.0297317504882812, -0.5329416990280151,\n",
      "        -0.12560749053955078, -0.2610955238342285, -0.9329736232757568, -0.09026432037353516]\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_env_steps_sampled: 5000\n",
      "  num_env_steps_trained: 128000\n",
      "  num_target_updates: 8\n",
      "iterations_since_restore: 5\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 5000\n",
      "num_agent_steps_trained: 128000\n",
      "num_env_steps_sampled: 5000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 29.108195029287184\n",
      "num_env_steps_trained: 128000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 931.4622409371899\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 58.29791666666666\n",
      "  ram_util_percent: 49.40625\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.189448063326896\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10361482274506947\n",
      "  mean_inference_ms: 2.036931447743581\n",
      "  mean_raw_obs_processing_ms: 1.227791337880385\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.010008096694946289\n",
      "    StateBufferConnector_ms: 0.00099945068359375\n",
      "    ViewRequirementAgentConnector_ms: 0.19654512405395508\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 26.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 87.0\n",
      "  episode_reward_mean: 26.38\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 33\n",
      "  hist_stats:\n",
      "    episode_lengths: [25, 16, 12, 25, 21, 11, 29, 25, 12, 10, 16, 11, 15, 20, 28,\n",
      "      15, 16, 41, 18, 29, 31, 10, 29, 18, 15, 24, 11, 17, 15, 17, 39, 15, 25, 21,\n",
      "      11, 15, 14, 28, 35, 37, 36, 27, 24, 12, 64, 12, 69, 24, 19, 25, 13, 18, 33,\n",
      "      26, 15, 75, 50, 75, 15, 24, 41, 12, 25, 22, 53, 13, 10, 39, 62, 25, 18, 28,\n",
      "      20, 20, 9, 9, 21, 18, 33, 15, 35, 32, 18, 31, 23, 27, 36, 54, 21, 32, 30, 39,\n",
      "      39, 51, 13, 19, 32, 29, 19, 87]\n",
      "    episode_reward: [25.0, 16.0, 12.0, 25.0, 21.0, 11.0, 29.0, 25.0, 12.0, 10.0, 16.0,\n",
      "      11.0, 15.0, 20.0, 28.0, 15.0, 16.0, 41.0, 18.0, 29.0, 31.0, 10.0, 29.0, 18.0,\n",
      "      15.0, 24.0, 11.0, 17.0, 15.0, 17.0, 39.0, 15.0, 25.0, 21.0, 11.0, 15.0, 14.0,\n",
      "      28.0, 35.0, 37.0, 36.0, 27.0, 24.0, 12.0, 64.0, 12.0, 69.0, 24.0, 19.0, 25.0,\n",
      "      13.0, 18.0, 33.0, 26.0, 15.0, 75.0, 50.0, 75.0, 15.0, 24.0, 41.0, 12.0, 25.0,\n",
      "      22.0, 53.0, 13.0, 10.0, 39.0, 62.0, 25.0, 18.0, 28.0, 20.0, 20.0, 9.0, 9.0,\n",
      "      21.0, 18.0, 33.0, 15.0, 35.0, 32.0, 18.0, 31.0, 23.0, 27.0, 36.0, 54.0, 21.0,\n",
      "      32.0, 30.0, 39.0, 39.0, 51.0, 13.0, 19.0, 32.0, 29.0, 19.0, 87.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.189448063326896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10361482274506947\n",
      "    mean_inference_ms: 2.036931447743581\n",
      "    mean_raw_obs_processing_ms: 1.227791337880385\n",
      "time_since_restore: 144.5807991027832\n",
      "time_this_iter_s: 34.35658025741577\n",
      "time_total_s: 144.5807991027832\n",
      "timers:\n",
      "  learn_throughput: 3440.492\n",
      "  learn_time_ms: 9.301\n",
      "  load_throughput: 80015.338\n",
      "  load_time_ms: 0.4\n",
      "  sample_time_ms: 3.9\n",
      "  synch_weights_time_ms: 0.1\n",
      "  training_iteration_time_ms: 34.771\n",
      "timestamp: 1690869821\n",
      "timesteps_total: 5000\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 6000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.011993169784545898\n",
      "  StateBufferConnector_ms: 0.0019958019256591797\n",
      "  ViewRequirementAgentConnector_ms: 0.1982893943786621\n",
      "counters:\n",
      "  last_target_update_ts: 5501\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_trained: 160000\n",
      "  num_target_updates: 10\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-04-16\n",
      "done: false\n",
      "episode_len_mean: 32.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 154.0\n",
      "episode_reward_mean: 32.37\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 19\n",
      "episodes_total: 234\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 5501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 2199.0625\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.09614954888820648\n",
      "        max_q: 11.22130298614502\n",
      "        mean_q: 8.834429740905762\n",
      "        min_q: -0.8228214383125305\n",
      "      mean_td_error: 0.3080012798309326\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 5000.0\n",
      "      td_error: [0.03125762939453125, -0.11152076721191406, -0.007718086242675781,\n",
      "        4.540223121643066, -0.3981294631958008, -0.24623966217041016, 0.0038661956787109375,\n",
      "        -1.8228213787078857, 0.27657318115234375, -0.20794057846069336, -0.19135189056396484,\n",
      "        -0.16254806518554688, -0.06684017181396484, 0.033423423767089844, -0.11761093139648438,\n",
      "        0.0487060546875, -0.0883626937866211, -0.11914443969726562, 0.019911766052246094,\n",
      "        -0.014777183532714844, -0.13990402221679688, -0.02437877655029297, -0.12917137145996094,\n",
      "        -0.1484241485595703, -0.5648431777954102, 3.41864013671875, -0.10771560668945312,\n",
      "        0.01535797119140625, -0.1351795196533203, 0.06070518493652344, 6.115720748901367,\n",
      "        0.09627819061279297]\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_trained: 160000\n",
      "  num_target_updates: 10\n",
      "iterations_since_restore: 6\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 6000\n",
      "num_agent_steps_trained: 160000\n",
      "num_env_steps_sampled: 6000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.688949173419378\n",
      "num_env_steps_trained: 160000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 918.0463735494201\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 59.99791666666666\n",
      "  ram_util_percent: 49.541666666666664\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.18956285873881135\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.1043871830396715\n",
      "  mean_inference_ms: 2.0430496915879126\n",
      "  mean_raw_obs_processing_ms: 1.2291449513815609\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.011993169784545898\n",
      "    StateBufferConnector_ms: 0.0019958019256591797\n",
      "    ViewRequirementAgentConnector_ms: 0.1982893943786621\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 32.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 154.0\n",
      "  episode_reward_mean: 32.37\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 19\n",
      "  hist_stats:\n",
      "    episode_lengths: [29, 31, 10, 29, 18, 15, 24, 11, 17, 15, 17, 39, 15, 25, 21,\n",
      "      11, 15, 14, 28, 35, 37, 36, 27, 24, 12, 64, 12, 69, 24, 19, 25, 13, 18, 33,\n",
      "      26, 15, 75, 50, 75, 15, 24, 41, 12, 25, 22, 53, 13, 10, 39, 62, 25, 18, 28,\n",
      "      20, 20, 9, 9, 21, 18, 33, 15, 35, 32, 18, 31, 23, 27, 36, 54, 21, 32, 30, 39,\n",
      "      39, 51, 13, 19, 32, 29, 19, 87, 26, 13, 16, 112, 32, 18, 19, 34, 13, 52, 64,\n",
      "      23, 16, 44, 120, 154, 59, 45, 105]\n",
      "    episode_reward: [29.0, 31.0, 10.0, 29.0, 18.0, 15.0, 24.0, 11.0, 17.0, 15.0, 17.0,\n",
      "      39.0, 15.0, 25.0, 21.0, 11.0, 15.0, 14.0, 28.0, 35.0, 37.0, 36.0, 27.0, 24.0,\n",
      "      12.0, 64.0, 12.0, 69.0, 24.0, 19.0, 25.0, 13.0, 18.0, 33.0, 26.0, 15.0, 75.0,\n",
      "      50.0, 75.0, 15.0, 24.0, 41.0, 12.0, 25.0, 22.0, 53.0, 13.0, 10.0, 39.0, 62.0,\n",
      "      25.0, 18.0, 28.0, 20.0, 20.0, 9.0, 9.0, 21.0, 18.0, 33.0, 15.0, 35.0, 32.0,\n",
      "      18.0, 31.0, 23.0, 27.0, 36.0, 54.0, 21.0, 32.0, 30.0, 39.0, 39.0, 51.0, 13.0,\n",
      "      19.0, 32.0, 29.0, 19.0, 87.0, 26.0, 13.0, 16.0, 112.0, 32.0, 18.0, 19.0, 34.0,\n",
      "      13.0, 52.0, 64.0, 23.0, 16.0, 44.0, 120.0, 154.0, 59.0, 45.0, 105.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18956285873881135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1043871830396715\n",
      "    mean_inference_ms: 2.0430496915879126\n",
      "    mean_raw_obs_processing_ms: 1.2291449513815609\n",
      "time_since_restore: 179.4404318332672\n",
      "time_this_iter_s: 34.85963273048401\n",
      "time_total_s: 179.4404318332672\n",
      "timers:\n",
      "  learn_throughput: 3554.984\n",
      "  learn_time_ms: 9.001\n",
      "  load_throughput: 159859.133\n",
      "  load_time_ms: 0.2\n",
      "  sample_time_ms: 3.999\n",
      "  synch_weights_time_ms: 0.1\n",
      "  training_iteration_time_ms: 31.763\n",
      "timestamp: 1690869856\n",
      "timesteps_total: 6000\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 7000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.010993003845214844\n",
      "  StateBufferConnector_ms: 0.003997325897216797\n",
      "  ViewRequirementAgentConnector_ms: 0.21377825736999512\n",
      "counters:\n",
      "  last_target_update_ts: 6501\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 192000\n",
      "  num_env_steps_sampled: 7000\n",
      "  num_env_steps_trained: 192000\n",
      "  num_target_updates: 12\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-04-51\n",
      "done: false\n",
      "episode_len_mean: 39.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 39.4\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 16\n",
      "episodes_total: 250\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 6501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 2855.375\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.312945693731308\n",
      "        max_q: 13.534951210021973\n",
      "        mean_q: 9.542899131774902\n",
      "        min_q: -0.6643153429031372\n",
      "      mean_td_error: -0.11642230302095413\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 6000.0\n",
      "      td_error: [-0.019560813903808594, 0.004750251770019531, 0.08226299285888672,\n",
      "        -0.5090923309326172, -0.14852523803710938, -0.7753608226776123, -1.5827993154525757,\n",
      "        -0.07441329956054688, 0.0014715194702148438, -0.31516170501708984, 0.13499927520751953,\n",
      "        -1.6643153429031372, 0.04631614685058594, 0.021950721740722656, 0.3422703742980957,\n",
      "        4.142691612243652, -0.4571552276611328, -0.23277705907821655, 0.31944847106933594,\n",
      "        -0.37981700897216797, -0.05149078369140625, 0.04549884796142578, -0.07604789733886719,\n",
      "        0.12984180450439453, -0.8474941253662109, -1.0594854354858398, 0.38082027435302734,\n",
      "        -0.09477806091308594, 0.052023887634277344, -0.1564645767211914, -0.46396350860595703,\n",
      "        -0.5211575031280518]\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 192000\n",
      "  num_env_steps_sampled: 7000\n",
      "  num_env_steps_trained: 192000\n",
      "  num_target_updates: 12\n",
      "iterations_since_restore: 7\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 7000\n",
      "num_agent_steps_trained: 192000\n",
      "num_env_steps_sampled: 7000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.078336871813164\n",
      "num_env_steps_trained: 192000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 898.5067798980213\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 61.22653061224489\n",
      "  ram_util_percent: 49.61836734693877\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.1903967530265038\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10525170530134086\n",
      "  mean_inference_ms: 2.0520400186142616\n",
      "  mean_raw_obs_processing_ms: 1.23270093504161\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.010993003845214844\n",
      "    StateBufferConnector_ms: 0.003997325897216797\n",
      "    ViewRequirementAgentConnector_ms: 0.21377825736999512\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 39.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 39.4\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 16\n",
      "  hist_stats:\n",
      "    episode_lengths: [15, 14, 28, 35, 37, 36, 27, 24, 12, 64, 12, 69, 24, 19, 25,\n",
      "      13, 18, 33, 26, 15, 75, 50, 75, 15, 24, 41, 12, 25, 22, 53, 13, 10, 39, 62,\n",
      "      25, 18, 28, 20, 20, 9, 9, 21, 18, 33, 15, 35, 32, 18, 31, 23, 27, 36, 54, 21,\n",
      "      32, 30, 39, 39, 51, 13, 19, 32, 29, 19, 87, 26, 13, 16, 112, 32, 18, 19, 34,\n",
      "      13, 52, 64, 23, 16, 44, 120, 154, 59, 45, 105, 86, 52, 95, 16, 53, 80, 64, 112,\n",
      "      40, 27, 66, 200, 19, 38, 68, 14]\n",
      "    episode_reward: [15.0, 14.0, 28.0, 35.0, 37.0, 36.0, 27.0, 24.0, 12.0, 64.0, 12.0,\n",
      "      69.0, 24.0, 19.0, 25.0, 13.0, 18.0, 33.0, 26.0, 15.0, 75.0, 50.0, 75.0, 15.0,\n",
      "      24.0, 41.0, 12.0, 25.0, 22.0, 53.0, 13.0, 10.0, 39.0, 62.0, 25.0, 18.0, 28.0,\n",
      "      20.0, 20.0, 9.0, 9.0, 21.0, 18.0, 33.0, 15.0, 35.0, 32.0, 18.0, 31.0, 23.0,\n",
      "      27.0, 36.0, 54.0, 21.0, 32.0, 30.0, 39.0, 39.0, 51.0, 13.0, 19.0, 32.0, 29.0,\n",
      "      19.0, 87.0, 26.0, 13.0, 16.0, 112.0, 32.0, 18.0, 19.0, 34.0, 13.0, 52.0, 64.0,\n",
      "      23.0, 16.0, 44.0, 120.0, 154.0, 59.0, 45.0, 105.0, 86.0, 52.0, 95.0, 16.0, 53.0,\n",
      "      80.0, 64.0, 112.0, 40.0, 27.0, 66.0, 200.0, 19.0, 38.0, 68.0, 14.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1903967530265038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10525170530134086\n",
      "    mean_inference_ms: 2.0520400186142616\n",
      "    mean_raw_obs_processing_ms: 1.23270093504161\n",
      "time_since_restore: 215.05707573890686\n",
      "time_this_iter_s: 35.61664390563965\n",
      "time_total_s: 215.05707573890686\n",
      "timers:\n",
      "  learn_throughput: 3368.623\n",
      "  learn_time_ms: 9.499\n",
      "  load_throughput: 80053.518\n",
      "  load_time_ms: 0.4\n",
      "  sample_time_ms: 4.5\n",
      "  synch_weights_time_ms: 0.1\n",
      "  training_iteration_time_ms: 34.7\n",
      "timestamp: 1690869891\n",
      "timesteps_total: 7000\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 8000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.008994340896606445\n",
      "  StateBufferConnector_ms: 0.004994869232177734\n",
      "  ViewRequirementAgentConnector_ms: 0.21157026290893555\n",
      "counters:\n",
      "  last_target_update_ts: 7501\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 224000\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_trained: 224000\n",
      "  num_target_updates: 14\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-05-27\n",
      "done: false\n",
      "episode_len_mean: 42.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 42.14\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 272\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 7501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 3701.53125\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.7128821611404419\n",
      "        max_q: 15.757835388183594\n",
      "        mean_q: 9.90528392791748\n",
      "        min_q: -0.9369664788246155\n",
      "      mean_td_error: -0.6002687215805054\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 7000.0\n",
      "      td_error: [0.053910255432128906, 1.0556097030639648, 0.05018806457519531, -0.2865498661994934,\n",
      "        -1.132584571838379, -0.08370399475097656, -2.8317809104919434, -0.0867910385131836,\n",
      "        -0.8595829010009766, 0.9896950721740723, 0.3305950164794922, -1.0860300064086914,\n",
      "        -0.6598196029663086, -0.3810710906982422, -0.48474740982055664, -5.80217170715332,\n",
      "        -0.6002559661865234, -1.779900074005127, -1.9369664192199707, -2.038968086242676,\n",
      "        -0.0886983871459961, -0.35562801361083984, -0.12079524993896484, -1.3028146028518677,\n",
      "        -0.23619747161865234, -0.07898998260498047, 0.08879661560058594, 0.1790018081665039,\n",
      "        -0.09283256530761719, 0.44396018981933594, -0.05351829528808594, -0.019957542419433594]\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 224000\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_trained: 224000\n",
      "  num_target_updates: 14\n",
      "iterations_since_restore: 8\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 8000\n",
      "num_agent_steps_trained: 224000\n",
      "num_env_steps_sampled: 8000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.37589668674868\n",
      "num_env_steps_trained: 224000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 908.0286939759577\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 61.01632653061225\n",
      "  ram_util_percent: 49.73265306122448\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.19136450644843897\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10605801355456146\n",
      "  mean_inference_ms: 2.0586274148324626\n",
      "  mean_raw_obs_processing_ms: 1.237179439979659\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.008994340896606445\n",
      "    StateBufferConnector_ms: 0.004994869232177734\n",
      "    ViewRequirementAgentConnector_ms: 0.21157026290893555\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 42.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 42.14\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 22\n",
      "  hist_stats:\n",
      "    episode_lengths: [75, 15, 24, 41, 12, 25, 22, 53, 13, 10, 39, 62, 25, 18, 28,\n",
      "      20, 20, 9, 9, 21, 18, 33, 15, 35, 32, 18, 31, 23, 27, 36, 54, 21, 32, 30, 39,\n",
      "      39, 51, 13, 19, 32, 29, 19, 87, 26, 13, 16, 112, 32, 18, 19, 34, 13, 52, 64,\n",
      "      23, 16, 44, 120, 154, 59, 45, 105, 86, 52, 95, 16, 53, 80, 64, 112, 40, 27,\n",
      "      66, 200, 19, 38, 68, 14, 63, 68, 54, 88, 27, 93, 17, 14, 46, 25, 53, 106, 17,\n",
      "      31, 103, 18, 18, 20, 18, 19, 20, 27]\n",
      "    episode_reward: [75.0, 15.0, 24.0, 41.0, 12.0, 25.0, 22.0, 53.0, 13.0, 10.0, 39.0,\n",
      "      62.0, 25.0, 18.0, 28.0, 20.0, 20.0, 9.0, 9.0, 21.0, 18.0, 33.0, 15.0, 35.0,\n",
      "      32.0, 18.0, 31.0, 23.0, 27.0, 36.0, 54.0, 21.0, 32.0, 30.0, 39.0, 39.0, 51.0,\n",
      "      13.0, 19.0, 32.0, 29.0, 19.0, 87.0, 26.0, 13.0, 16.0, 112.0, 32.0, 18.0, 19.0,\n",
      "      34.0, 13.0, 52.0, 64.0, 23.0, 16.0, 44.0, 120.0, 154.0, 59.0, 45.0, 105.0, 86.0,\n",
      "      52.0, 95.0, 16.0, 53.0, 80.0, 64.0, 112.0, 40.0, 27.0, 66.0, 200.0, 19.0, 38.0,\n",
      "      68.0, 14.0, 63.0, 68.0, 54.0, 88.0, 27.0, 93.0, 17.0, 14.0, 46.0, 25.0, 53.0,\n",
      "      106.0, 17.0, 31.0, 103.0, 18.0, 18.0, 20.0, 18.0, 19.0, 20.0, 27.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.19136450644843897\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10605801355456146\n",
      "    mean_inference_ms: 2.0586274148324626\n",
      "    mean_raw_obs_processing_ms: 1.237179439979659\n",
      "time_since_restore: 250.2992525100708\n",
      "time_this_iter_s: 35.24217677116394\n",
      "time_total_s: 250.2992525100708\n",
      "timers:\n",
      "  learn_throughput: 3478.928\n",
      "  learn_time_ms: 9.198\n",
      "  load_throughput: 106632.024\n",
      "  load_time_ms: 0.3\n",
      "  sample_time_ms: 3.999\n",
      "  synch_weights_time_ms: 0.1\n",
      "  training_iteration_time_ms: 32.7\n",
      "timestamp: 1690869927\n",
      "timesteps_total: 8000\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 9000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.010987281799316406\n",
      "  StateBufferConnector_ms: 0.0059964656829833984\n",
      "  ViewRequirementAgentConnector_ms: 0.20958185195922852\n",
      "counters:\n",
      "  last_target_update_ts: 8501\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 256000\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_trained: 256000\n",
      "  num_target_updates: 16\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-06-02\n",
      "done: false\n",
      "episode_len_mean: 50.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 50.66\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 7\n",
      "episodes_total: 279\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 8501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 3787.5625\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.552118718624115\n",
      "        max_q: 17.441892623901367\n",
      "        mean_q: 13.821388244628906\n",
      "        min_q: 2.6588869094848633\n",
      "      mean_td_error: -0.0964585393667221\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 8000.0\n",
      "      td_error: [-1.219888687133789, 0.033257484436035156, -1.4422831535339355, -2.3408126831054688,\n",
      "        0.15770721435546875, 0.001956939697265625, -0.06659126281738281, 0.1906595230102539,\n",
      "        0.07291221618652344, -0.08228588104248047, -0.45481395721435547, 0.3739757537841797,\n",
      "        0.32380104064941406, 0.04977607727050781, 0.21101760864257812, 1.0102519989013672,\n",
      "        -0.30486583709716797, -0.11365699768066406, 0.6440954208374023, 0.26813316345214844,\n",
      "        0.577336311340332, 0.22383499145507812, -1.0667848587036133, 0.7626810073852539,\n",
      "        -0.009063720703125, -0.014779090881347656, 1.6588869094848633, 0.09123992919921875,\n",
      "        -1.714874267578125, -0.8715934753417969, -0.04870033264160156, 0.012797355651855469]\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 256000\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_trained: 256000\n",
      "  num_target_updates: 16\n",
      "iterations_since_restore: 9\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 9000\n",
      "num_agent_steps_trained: 256000\n",
      "num_env_steps_sampled: 9000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 28.381123912005513\n",
      "num_env_steps_trained: 256000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 908.1959651841764\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 61.230612244897955\n",
      "  ram_util_percent: 49.81224489795919\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.191678696629426\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10638215659542091\n",
      "  mean_inference_ms: 2.061016890321271\n",
      "  mean_raw_obs_processing_ms: 1.2387446765763184\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.010987281799316406\n",
      "    StateBufferConnector_ms: 0.0059964656829833984\n",
      "    ViewRequirementAgentConnector_ms: 0.20958185195922852\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 50.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 50.66\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 7\n",
      "  hist_stats:\n",
      "    episode_lengths: [53, 13, 10, 39, 62, 25, 18, 28, 20, 20, 9, 9, 21, 18, 33, 15,\n",
      "      35, 32, 18, 31, 23, 27, 36, 54, 21, 32, 30, 39, 39, 51, 13, 19, 32, 29, 19,\n",
      "      87, 26, 13, 16, 112, 32, 18, 19, 34, 13, 52, 64, 23, 16, 44, 120, 154, 59, 45,\n",
      "      105, 86, 52, 95, 16, 53, 80, 64, 112, 40, 27, 66, 200, 19, 38, 68, 14, 63, 68,\n",
      "      54, 88, 27, 93, 17, 14, 46, 25, 53, 106, 17, 31, 103, 18, 18, 20, 18, 19, 20,\n",
      "      27, 97, 32, 183, 154, 200, 200, 200]\n",
      "    episode_reward: [53.0, 13.0, 10.0, 39.0, 62.0, 25.0, 18.0, 28.0, 20.0, 20.0, 9.0,\n",
      "      9.0, 21.0, 18.0, 33.0, 15.0, 35.0, 32.0, 18.0, 31.0, 23.0, 27.0, 36.0, 54.0,\n",
      "      21.0, 32.0, 30.0, 39.0, 39.0, 51.0, 13.0, 19.0, 32.0, 29.0, 19.0, 87.0, 26.0,\n",
      "      13.0, 16.0, 112.0, 32.0, 18.0, 19.0, 34.0, 13.0, 52.0, 64.0, 23.0, 16.0, 44.0,\n",
      "      120.0, 154.0, 59.0, 45.0, 105.0, 86.0, 52.0, 95.0, 16.0, 53.0, 80.0, 64.0, 112.0,\n",
      "      40.0, 27.0, 66.0, 200.0, 19.0, 38.0, 68.0, 14.0, 63.0, 68.0, 54.0, 88.0, 27.0,\n",
      "      93.0, 17.0, 14.0, 46.0, 25.0, 53.0, 106.0, 17.0, 31.0, 103.0, 18.0, 18.0, 20.0,\n",
      "      18.0, 19.0, 20.0, 27.0, 97.0, 32.0, 183.0, 154.0, 200.0, 200.0, 200.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.191678696629426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10638215659542091\n",
      "    mean_inference_ms: 2.061016890321271\n",
      "    mean_raw_obs_processing_ms: 1.2387446765763184\n",
      "time_since_restore: 285.5349383354187\n",
      "time_this_iter_s: 35.2356858253479\n",
      "time_total_s: 285.5349383354187\n",
      "timers:\n",
      "  learn_throughput: 2559.756\n",
      "  learn_time_ms: 12.501\n",
      "  load_throughput: 159783.01\n",
      "  load_time_ms: 0.2\n",
      "  sample_time_ms: 4.2\n",
      "  synch_weights_time_ms: 0.2\n",
      "  training_iteration_time_ms: 35.9\n",
      "timestamp: 1690869962\n",
      "timesteps_total: 9000\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 10000\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.011983156204223633\n",
      "  StateBufferConnector_ms: 0.0059964656829833984\n",
      "  ViewRequirementAgentConnector_ms: 0.20610308647155762\n",
      "counters:\n",
      "  last_target_update_ts: 9501\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 288000\n",
      "  num_env_steps_sampled: 10000\n",
      "  num_env_steps_trained: 288000\n",
      "  num_target_updates: 18\n",
      "custom_metrics: {}\n",
      "date: 2023-08-01_15-06-38\n",
      "done: false\n",
      "episode_len_mean: 57.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 57.5\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 12\n",
      "episodes_total: 291\n",
      "hostname: DESKTOP-TSBOB2F\n",
      "info:\n",
      "  last_target_update_ts: 9501\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 4067.96875\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.3580845892429352\n",
      "        max_q: 19.460914611816406\n",
      "        mean_q: 15.274151802062988\n",
      "        min_q: 1.5033584833145142\n",
      "      mean_td_error: -0.07546131312847137\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 32.0\n",
      "      num_grad_updates_lifetime: 9000.0\n",
      "      td_error: [-0.12864303588867188, 0.11456680297851562, -0.57763671875, -0.7842159271240234,\n",
      "        -0.06214714050292969, -0.355560302734375, -0.1554412841796875, 0.18311309814453125,\n",
      "        0.0018768310546875, 0.23905563354492188, 3.287688732147217, -0.57763671875,\n",
      "        0.5033584833145142, -0.22841453552246094, 0.21744918823242188, 1.1238465309143066,\n",
      "        0.1826000213623047, 0.7586617469787598, -0.08434486389160156, -1.1407604217529297,\n",
      "        0.7580975294113159, 0.07225799560546875, -3.327383041381836, 0.3166007995605469,\n",
      "        -3.0223445892333984, -0.10950088500976562, -0.10368919372558594, 0.374326229095459,\n",
      "        0.25069618225097656, -0.23519134521484375, 0.2986011505126953, -0.2046489715576172]\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 288000\n",
      "  num_env_steps_sampled: 10000\n",
      "  num_env_steps_trained: 288000\n",
      "  num_target_updates: 18\n",
      "iterations_since_restore: 10\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 10000\n",
      "num_agent_steps_trained: 288000\n",
      "num_env_steps_sampled: 10000\n",
      "num_env_steps_sampled_this_iter: 1000\n",
      "num_env_steps_sampled_throughput_per_sec: 27.871806928324006\n",
      "num_env_steps_trained: 288000\n",
      "num_env_steps_trained_this_iter: 32000\n",
      "num_env_steps_trained_throughput_per_sec: 891.8978217063682\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 32000\n",
      "perf:\n",
      "  cpu_util_percent: 59.82200000000001\n",
      "  ram_util_percent: 49.80200000000001\n",
      "pid: 27436\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.19208870392075775\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.10714782339498634\n",
      "  mean_inference_ms: 2.066524289207577\n",
      "  mean_raw_obs_processing_ms: 1.2418119877325613\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.011983156204223633\n",
      "    StateBufferConnector_ms: 0.0059964656829833984\n",
      "    ViewRequirementAgentConnector_ms: 0.20610308647155762\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 57.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 200.0\n",
      "  episode_reward_mean: 57.5\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 12\n",
      "  hist_stats:\n",
      "    episode_lengths: [21, 18, 33, 15, 35, 32, 18, 31, 23, 27, 36, 54, 21, 32, 30,\n",
      "      39, 39, 51, 13, 19, 32, 29, 19, 87, 26, 13, 16, 112, 32, 18, 19, 34, 13, 52,\n",
      "      64, 23, 16, 44, 120, 154, 59, 45, 105, 86, 52, 95, 16, 53, 80, 64, 112, 40,\n",
      "      27, 66, 200, 19, 38, 68, 14, 63, 68, 54, 88, 27, 93, 17, 14, 46, 25, 53, 106,\n",
      "      17, 31, 103, 18, 18, 20, 18, 19, 20, 27, 97, 32, 183, 154, 200, 200, 200, 78,\n",
      "      101, 14, 33, 36, 200, 16, 200, 17, 93, 103, 99]\n",
      "    episode_reward: [21.0, 18.0, 33.0, 15.0, 35.0, 32.0, 18.0, 31.0, 23.0, 27.0, 36.0,\n",
      "      54.0, 21.0, 32.0, 30.0, 39.0, 39.0, 51.0, 13.0, 19.0, 32.0, 29.0, 19.0, 87.0,\n",
      "      26.0, 13.0, 16.0, 112.0, 32.0, 18.0, 19.0, 34.0, 13.0, 52.0, 64.0, 23.0, 16.0,\n",
      "      44.0, 120.0, 154.0, 59.0, 45.0, 105.0, 86.0, 52.0, 95.0, 16.0, 53.0, 80.0, 64.0,\n",
      "      112.0, 40.0, 27.0, 66.0, 200.0, 19.0, 38.0, 68.0, 14.0, 63.0, 68.0, 54.0, 88.0,\n",
      "      27.0, 93.0, 17.0, 14.0, 46.0, 25.0, 53.0, 106.0, 17.0, 31.0, 103.0, 18.0, 18.0,\n",
      "      20.0, 18.0, 19.0, 20.0, 27.0, 97.0, 32.0, 183.0, 154.0, 200.0, 200.0, 200.0,\n",
      "      78.0, 101.0, 14.0, 33.0, 36.0, 200.0, 16.0, 200.0, 17.0, 93.0, 103.0, 99.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.19208870392075775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.10714782339498634\n",
      "    mean_inference_ms: 2.066524289207577\n",
      "    mean_raw_obs_processing_ms: 1.2418119877325613\n",
      "time_since_restore: 321.4154872894287\n",
      "time_this_iter_s: 35.88054895401001\n",
      "time_total_s: 321.4154872894287\n",
      "timers:\n",
      "  learn_throughput: 3018.693\n",
      "  learn_time_ms: 10.601\n",
      "  load_throughput: 106716.807\n",
      "  load_time_ms: 0.3\n",
      "  sample_time_ms: 3.701\n",
      "  synch_weights_time_ms: 0.0\n",
      "  training_iteration_time_ms: 34.5\n",
      "timestamp: 1690869998\n",
      "timesteps_total: 10000\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "# config = PPOConfig()\n",
    "config = DQNConfig()\n",
    "print(config)\n",
    "\n",
    "algo = config.resources(num_gpus=0).environment(\"CartPole-v0\").build()\n",
    "\n",
    "for i in range(10):\n",
    "    result = algo.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'C:\\\\Users\\\\lcglab/ray_results\\\\PPO_CartPole-v0_2023-08-01_14-15-57v3dx_mi1\\\\model'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.export_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo.export_policy_model(\"policy_model\", onnx=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get(\"_enable_rl_module_api\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
