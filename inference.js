// import * as ort from "onnxruntime-web";


console.log("Hello World! from test.js")
// console.log(ort.version());

// // Load the model and create InferenceSession
// const modelPath = "rl/policy_model/model.onnx";
// const session = await ort.InferenceSession.create(modelPath);

// // Load and preprocess the input obs to inputTensor
// const obs = [0.1, 0.2, 0.3, 0.4];
// const inputTensor = new ort.Tensor("float32", obs, [1, 4]);

// // Run inference
// const outputs = await session.run({ input: inputTensor });
// console.log(outputs);