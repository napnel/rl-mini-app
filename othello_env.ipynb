{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:24:01,850\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:24:02,522\tWARNING deprecation.py:50 -- DeprecationWarning: `build_tf_policy` has been deprecated. This will raise an error in the future!\n",
      "2023-08-14 19:24:02,546\tWARNING deprecation.py:50 -- DeprecationWarning: `build_policy_class` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.algorithms import ppo, dqn, appo, impala\n",
    "from ray.rllib.policy.policy import PolicySpec, Policy\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.examples.policy.random_policy import RandomPolicy\n",
    "from rl.envs.othello import OthelloEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env(\"othello\", lambda _: OthelloEnv({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "action = gym.spaces.Box(-1, 1, shape=(1, 1), dtype=np.float32).sample()\n",
    "type(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "\n",
    "\n",
    "class OthelloRandomPolicy(RandomPolicy):\n",
    "    @override(Policy)\n",
    "    def compute_actions(self, obs_batch, **kwargs):\n",
    "        actions: List[int] = [\n",
    "            self._valid_random_action(obs) for obs in obs_batch\n",
    "        ] \n",
    "        return actions, [], {}\n",
    "\n",
    "    def _valid_random_action(self, obs) -> int:\n",
    "        valid_actions: List[int] = []\n",
    "        for row in range(obs.shape[0]):\n",
    "            for col in range(obs.shape[1]):\n",
    "                if self._is_valid_action(obs, row, col):\n",
    "                    valid_actions.append(row * obs.shape[0] + col)\n",
    "\n",
    "        return random.choice(valid_actions)\n",
    "\n",
    "    def _is_valid_move(self, row: int, col: int) -> bool:\n",
    "        if row < 0 or row > 7 or col < 0 or col > 7 or self.board[row][col] != 0:\n",
    "            return False\n",
    "\n",
    "        marks = {\"agent_1\": 1, \"agent_2\": -1, \"empty\": 0}\n",
    "        agent_id = marks[self.__policy_id]\n",
    "        directions = [\n",
    "            (1, 0),\n",
    "            (-1, 0),\n",
    "            (0, 1),\n",
    "            (0, -1),\n",
    "            (1, 1),\n",
    "            (1, -1),\n",
    "            (-1, 1),\n",
    "            (-1, -1),\n",
    "        ]\n",
    "\n",
    "        for d_row, d_col in directions:\n",
    "            r, c = row + d_row, col + d_col\n",
    "            if 0 <= r < 8 and 0 <= c < 8 and self.board[r][c] == -agent_id:\n",
    "                r += d_row\n",
    "                c += d_col\n",
    "                while 0 <= r < 8 and 0 <= c < 8 and self.board[r][c] == -agent_id:\n",
    "                    r += d_row\n",
    "                    c += d_col\n",
    "                if 0 <= r < 8 and 0 <= c < 8 and self.board[r][c] == agent_id:\n",
    "                    return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:24:02,837\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-08-14 19:24:02,874\tWARNING algorithm_config.py:2572 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    agent_id = int(agent_id[-1]) - 1\n",
    "    return \"agent_1\" if episode.episode_id % 2 == agent_id else \"agent_2\"\n",
    "\n",
    "config = ppo.PPOConfig().environment(\"othello\").framework(\"torch\").rollouts(num_rollout_workers=os.cpu_count() // 2).resources(num_gpus=0)\n",
    "config = config.multi_agent(policies={\"agent_1\": PolicySpec(), \"agent_2\": PolicySpec(policy_class=OthelloRandomPolicy)}, policy_mapping_fn=policy_mapping_fn, policies_to_train=[\"agent_1\"])\n",
    "config = config.training(model={\"fcnet_hiddens\": [512, 512]}, _enable_learner_api=False)\n",
    "# config = config.training(num_sgd_iter=10, model={\"conv_filters\": [[32, [3, 3], 1], [64, [3, 3], 1]]})\n",
    "# config = config.training(model={\"conv_filters\": [[32, [3, 3], 2], [64, [3, 3], 2]]}, _enable_learner_api=False)\n",
    "# config = config.training(_enable_learner_api=False)\n",
    "config = config.rl_module(_enable_rl_module_api=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# # multiagent environment for othello\n",
    "# env = OthelloEnv({})\n",
    "# obs, _ = env.reset()\n",
    "# terminated = False\n",
    "# current_player = \"agent_1\"\n",
    "# while not terminated:\n",
    "#     env.render()\n",
    "#     # action = env.action_space.sample()\n",
    "#     valid_actions = env.get_valid_moves(current_player)\n",
    "#     print(current_player, obs.keys())\n",
    "#     print(obs[current_player].shape)\n",
    "#     action = algo.compute_single_action(obs[current_player], policy_id=current_player)\n",
    "#     print(action)\n",
    "#     if len(valid_actions) > 0:\n",
    "#         action = random.choice(valid_actions)\n",
    "#     else:\n",
    "#         action = 64\n",
    "#     action = {current_player: action}\n",
    "#     obs, reward, terminated, truncated, _= env.step(action)\n",
    "#     reward = reward[current_player]\n",
    "#     terminated = terminated[current_player]\n",
    "#     truncated = truncated[current_player]\n",
    "#     current_player = env.current_player\n",
    "#     print(terminated, truncated, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-14 19:26:07</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:41.60        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.4/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_othello_be570_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:24:25,970\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-08-14 19:24:25,974\tWARNING algorithm_config.py:2572 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "\u001b[2m\u001b[36m(pid=1920)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=1920)\u001b[0m 2023-08-14 19:25:01,791\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(PPO pid=1920)\u001b[0m 2023-08-14 19:25:01,791\tWARNING algorithm_config.py:2572 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "\u001b[2m\u001b[36m(PPO pid=1920)\u001b[0m 2023-08-14 19:25:01,792\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n"
     ]
    }
   ],
   "source": [
    "from ray import air\n",
    "from ray import tune\n",
    "\n",
    "results = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config,\n",
    "    run_config=air.RunConfig(\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_at_end=True,\n",
    "            checkpoint_frequency=50,\n",
    "        )\n",
    "    ),\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    error='TuneError',\n",
       "    metrics={'trial_id': 'fef35_00000'},\n",
       "    path='c://\\\\Users\\\\lcglab\\\\ray_results\\\\IMPALA\\\\IMPALA_othello_fef35_00000_0_2023-08-11_00-17-18',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,050\tERROR actor_manager.py:500 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16064, ip=127.0.0.1, actor_id=77c468a4531990bdcb4240c601000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022313862700>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,051\tERROR actor_manager.py:500 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=20296, ip=127.0.0.1, actor_id=372fccaccb72cea83aceffba01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000002AAB44826A0>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,051\tERROR actor_manager.py:500 -- Ray error, taking actor 3 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=15428, ip=127.0.0.1, actor_id=6679da3f6703374ea0ce886801000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000002274D3FF5E0>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,051\tERROR actor_manager.py:500 -- Ray error, taking actor 4 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=15324, ip=127.0.0.1, actor_id=19a9573420aac0bfc49606b901000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000021B12DC26D0>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,052\tERROR actor_manager.py:500 -- Ray error, taking actor 5 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=22524, ip=127.0.0.1, actor_id=2e3165ac245dd77f6e9d00fd01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000253529F2610>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,052\tERROR actor_manager.py:500 -- Ray error, taking actor 6 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=20316, ip=127.0.0.1, actor_id=49fb9387779f9c9a0f68ffbc01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000239A8322730>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,052\tERROR actor_manager.py:500 -- Ray error, taking actor 7 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16036, ip=127.0.0.1, actor_id=d7541886a9fedfcd553e9b3d01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000018080F226D0>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,052\tERROR actor_manager.py:500 -- Ray error, taking actor 8 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=21400, ip=127.0.0.1, actor_id=5f789962ac1608bcfc3a3aff01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000232EAAD2700>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,053\tERROR actor_manager.py:500 -- Ray error, taking actor 9 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16304, ip=127.0.0.1, actor_id=73a1af5f295af4c4e213db2401000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001B7A5722700>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,053\tERROR actor_manager.py:500 -- Ray error, taking actor 10 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=8624, ip=127.0.0.1, actor_id=2e1c37b104dfe99a61a9584a01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000221456F26A0>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,053\tERROR actor_manager.py:500 -- Ray error, taking actor 11 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=10460, ip=127.0.0.1, actor_id=1a59927e65df9a38e9ddeca201000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000234F6112730>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m 2023-08-11 00:17:38,053\tERROR actor_manager.py:500 -- Ray error, taking actor 12 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=1964, ip=127.0.0.1, actor_id=eaf0520ba9365d37371ab5f801000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000261FF432700>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::Impala.__init__()\u001b[39m (pid=21228, ip=127.0.0.1, actor_id=5c712c23a1ef3c061805ce6901000000, repr=Impala)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 227, in _setup\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self.add_workers(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 593, in add_workers\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     raise result.get()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py\", line 481, in __fetch_result\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     result = ray.get(r)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\worker.py\", line 2495, in get\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     raise value\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16064, ip=127.0.0.1, actor_id=77c468a4531990bdcb4240c601000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022313862700>)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 525, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._update_policy_map(policy_dict=self.policy_dict)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1727, in _update_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 1838, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     new_policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\utils\\policy.py\", line 142, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala_torch_policy.py\", line 227, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self._initialize_loss_from_dummy_batch()\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\policy\\policy.py\", line 1407, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     max(self.batch_divisibility_req * 4, 32),\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m \u001b[36mray::Impala.__init__()\u001b[39m (pid=21228, ip=127.0.0.1, actor_id=5c712c23a1ef3c061805ce6901000000, repr=Impala)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1418, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1498, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 517, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     super().__init__(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 169, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\impala\\impala.py\", line 615, in setup\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     super().setup(config)\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 639, in setup\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     self.workers = WorkerSet(\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m   File \"c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 179, in __init__\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m     raise e.args[0].args[2]\n",
      "\u001b[2m\u001b[36m(Impala pid=21228)\u001b[0m TypeError: '>' not supported between instances of 'int' and 'str'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1964)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=1964, ip=127.0.0.1, actor_id=eaf0520ba9365d37371ab5f801000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000261FF432700>)\n"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "checkpoint = results.get_best_result().checkpoint\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "register_env(\"othello\", lambda _: OthelloEnv({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 00:17:41,280\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2023-08-11 00:17:46,143\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(pid=19176)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,515\tWARNING multi_agent_env.py:169 -- observation_space_contains() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,516\tWARNING multi_agent_env.py:169 -- observation_space_contains() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,516\tWARNING multi_agent_env.py:169 -- observation_space_contains() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,516\tWARNING multi_agent_env.py:237 -- action_space_sample() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,517\tWARNING multi_agent_env.py:169 -- observation_space_contains() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,520\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19176)\u001b[0m 2023-08-11 00:17:56,568\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,643\tWARNING multi_agent_env.py:274 -- observation_space_sample() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,644\tWARNING multi_agent_env.py:199 -- action_space_contains() of <OthelloEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,653\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,653\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,673\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,673\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,673\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,674\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,674\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,674\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,674\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=20592)\u001b[0m 2023-08-11 00:17:56,676\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-11 00:17:56,932\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-08-11 00:17:56,942\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:56,944\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,163\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,164\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,165\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,167\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,167\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,168\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:57,169\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "2023-08-11 00:17:59,558\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2023-08-11 00:17:59,577\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-08-11 00:17:59,702\tINFO trainable.py:172 -- Trainable.setup took 18.396 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-08-11 00:17:59,704\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m config\u001b[39m.\u001b[39mexpolore \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      2\u001b[0m algo \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mbuild()\n\u001b[1;32m----> 3\u001b[0m algo\u001b[39m.\u001b[39;49mrestore(checkpoint)\n",
      "File \u001b[1;32mc:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:830\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[1;34m(self, checkpoint_path, checkpoint_node_ip, fallback_to_latest)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, Checkpoint):\n\u001b[0;32m    828\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restore_from_checkpoint_obj(checkpoint_path)\n\u001b[1;32m--> 830\u001b[0m synced_from_cloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_load_checkpoint_from_cloud(checkpoint_path)\n\u001b[0;32m    832\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m synced_from_cloud \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    833\u001b[0m     \u001b[39m# If a checkpoint source IP is given\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     checkpoint_node_ip\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[39mand\u001b[39;00m checkpoint_node_ip \u001b[39m!=\u001b[39m ray\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_node_ip_address()\n\u001b[0;32m    839\u001b[0m ):\n\u001b[0;32m    840\u001b[0m     checkpoint \u001b[39m=\u001b[39m _get_checkpoint_from_remote_node(\n\u001b[0;32m    841\u001b[0m         checkpoint_path, checkpoint_node_ip\n\u001b[0;32m    842\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:681\u001b[0m, in \u001b[0;36mTrainable._maybe_load_checkpoint_from_cloud\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_load_checkpoint_from_cloud\u001b[39m(\u001b[39mself\u001b[39m, checkpoint_path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m    669\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a checkpoint from its corresponding location in remote storage\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39m    to `checkpoint_path`.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[39m    If a checkpoint already exists at `checkpoint_path`, the Trainable\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[39m        bool: True if the checkpoint was synced down successfully from cloud.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexists(checkpoint_path):\n\u001b[0;32m    682\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m             TrainableUtil\u001b[39m.\u001b[39mfind_checkpoint_dir(checkpoint_path)\n",
      "File \u001b[1;32mc:\\Users\\lcglab\\miniconda3\\envs\\rl\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "config.expolore = False\n",
    "algo = config.build()\n",
    "algo.restore(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algo.get_policy(\"agent_1\").export_model(\"othello_policy\", onnx=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|O|X|.|.|.\n",
      ".|.|.|X|O|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      "\n",
      "{'agent_1': 29}\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|O|O|O|.|.\n",
      ".|.|.|X|O|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      "\n",
      "{'agent_2': 37}\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|O|O|O|.|.\n",
      ".|.|.|X|X|X|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      "\n",
      "{'agent_1': 19}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# multiagent environment for othello\n",
    "env = OthelloEnv({})\n",
    "obs, _ = env.reset()\n",
    "terminated = False\n",
    "current_player = \"agent_1\"\n",
    "while not terminated:\n",
    "    env.render()\n",
    "    # action = env.action_space.sample()\n",
    "    valid_actions = env.get_valid_moves(current_player)\n",
    "    action = algo.compute_single_action(obs[current_player], policy_id=current_player)\n",
    "    # if len(valid_actions) > 0:\n",
    "    #     action = random.choice(valid_actions)\n",
    "    # else:\n",
    "    #     action = 64\n",
    "    action = {current_player: action}\n",
    "    print(action)\n",
    "    obs, reward, terminated, truncated, _= env.step(action)\n",
    "    reward = reward[current_player]\n",
    "    terminated = terminated[current_player]\n",
    "    truncated = truncated[current_player]\n",
    "    current_player = env.current_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|O|O|O|.|.\n",
      ".|.|.|X|X|X|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      ".|.|.|.|.|.|.|.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
